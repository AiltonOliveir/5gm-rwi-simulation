'''
This code gets the p2m files generated by InSite via simulation.py and writes the ray information in files.
Different from todb.py, it does not use a database (no episode.db).
One does not need to specify the number of scenes per episode because this information is obtained from
the JSON file and confirmed (redundancy) with the file 'sumoOutputInfoFileName.txt' at "run_dir".
'''
import os
import json
import numpy as np
import csv
from sys import argv

# now we don't need to recall config.py. We can simply specify folders below
# import config as c

from rwisimulation.tfrecord import SceneNotInEpisodeSequenceError
#from rwisimulation.tfrecord import UnexpectedCarsWithAntennaChangeError, EpisodeNotStartingFromZeroError
# from rwimodeling import objects
from rwiparsing import P2mPaths
from rwiparsing import P2mCir

if len(argv) != 2:
    print('You need to specify the folder that has the output files written by the simulator!')
    print('Usage: python', argv[0], 'input_folder')
    exit(-1)

numScenesPerEpisode = 80 #50
numTxRxPairsPerScene = 10
numRaysPerTxRxPair = 100
numParametersPerRay = 7 + 1 #has the ray angle now

# from rwisimulation.datamodel import save5gmdata as fgdb

def base_run_dir_fn(i):  # the folders will be run00001, run00002, etc.
    """returns the `run_dir` for run `i`"""
    return "run{:05d}".format(i)


last_simulation_info = None
simulation_info = None
# session = fgdb.Session()

# Object which will be modified in the RWI project
# base_insite_project_path = 'D:/insitedata/insite_new_simuls/'
# Folder to store each InSite project and its results (will create subfolders for each "run", run0000, run0001, etc.)
results_dir = argv[1]  # 'D:/owncloud-lasse/5GM_DATA/flat_simulation/results_new_lidar/'

# The info below typically does not change
# dst_object_file_nameBaseName = "random-line.object"
# Ray-tracing output folder (where InSite will store the results (Study Area name)).
# They will be later copied to the corresponding output folder specified by results_dir
project_output_dirBaseName = 'study'
# Name (basename) of the paths file generated in the simulation
paths_file_name = 'model.paths.t001_01.r002.p2m'
# Output files, which are written by the Python scripts
# Name (basename) of the JSON output simulation info file
simulation_info_file_name = 'wri-simulation.info'

sc_i = 0
ep_i = -1  # it's summed to 1 and we need to start by 0
#episode = None
# n_run = 100000
run_i = 0
should_stop = False
while not should_stop:
    allEpisodeData = np.zeros((numScenesPerEpisode, numTxRxPairsPerScene, numRaysPerTxRxPair,
                               numParametersPerRay), np.float32)
    allEpisodeData.fill(np.nan)
    for s in range(numScenesPerEpisode):
        # for run_i in range(100): # use the number of examples in config.py
        run_dir = os.path.join(results_dir, base_run_dir_fn(run_i))
        # object_file_name = os.path.join(run_dir, dst_object_file_nameBaseName)
        # rays information but phase
        abs_paths_file_name = os.path.join(run_dir, project_output_dirBaseName, paths_file_name)
        if os.path.exists(abs_paths_file_name) == False:
            print('\nWarning: could not find file ', abs_paths_file_name, ' Stopping...')
            should_stop = True
            break
        # now we get the phase info from CIR file
        abs_cir_file_name = abs_paths_file_name.replace("paths", "cir")  # name for the impulse response (cir) file
        if os.path.exists(abs_cir_file_name) == False:
            print('ERROR: could not find file ', abs_cir_file_name)
            print('Did you ask InSite to generate the impulse response (cir) file?')
            exit(-1)

        abs_simulation_info_file_name = os.path.join(run_dir, simulation_info_file_name)
        with open(abs_simulation_info_file_name) as infile:
            simulation_info = json.load(infile)

        # start of episode
        if simulation_info['scene_i'] == 0:
            ep_i += 1
            this_scene_i = 0  # reset counter
            # if episode is not None:
            #    session.add(episode)
            #    session.commit()

            # read SUMO information for this scene from text CSV file
            sumoOutputInfoFileName = os.path.join(run_dir, 'sumoOutputInfoFileName.txt')
            with open(sumoOutputInfoFileName, 'r') as f:
                sumoReader = csv.reader(
                    f)  # AK-TODO ended up not using the CSV because the string is protected by " " I guess
                for row in sumoReader:
                    headerItems = row[0].split(',')
                    TsString = headerItems[-1]
                    try:
                        Ts = TsString.split('=')[1]
                        timeString = headerItems[-2]
                        time = timeString.split('=')[1]
                    except IndexError:  # old format
                        Ts = 0.005  # initialize values
                        time = -1
                    break  # process only first 2 rows / line AK-TODO should eliminate the loop
                for row in sumoReader:
                    # secondRow = row[1].split(',')
                    thisEpisodeNumber = int(row[0])
                    if thisEpisodeNumber != ep_i:
                        print('ERROR: thisEpisodeNumber != ep_i. They are:', thisEpisodeNumber, 'and', ep_i,
                              'file: ', sumoOutputInfoFileName, 'read:', row)
                        exit(1)
                    break  # process only first 2 rows / line AK-TODO should eliminate the loop
            # episode = fgdb.Episode(
            #    insite_pah=run_dir,
            #    sumo_path=sumoOutputInfoFileName,
            #    simulation_time_begin=time, #in milliseconds
            #    sampling_time=Ts, #in seconds
            # )

        #if episode is None:
        #    raise EpisodeNotStartingFromZeroError("From file {}".format(object_file_name))

        if simulation_info['scene_i'] != this_scene_i:
            raise SceneNotInEpisodeSequenceError('Expecting {} found {}'.format(
                this_scene_i,
                simulation_info['scene_i'],
            ))

        # with open(object_file_name) as infile:
        #    obj_file = objects.ObjectFile.from_file(infile)
        print(abs_paths_file_name)  # AK TODO take out this comment and use logging
        paths = P2mPaths(abs_paths_file_name)
        cir = P2mCir(abs_cir_file_name)

        # scene = fgdb.Scene()
        # scene.study_area = ((0, 0, 0), (0, 0, 0))

        rec_i = 0
        if paths.get_total_received_power(rec_i + 1) is not None:
            total_received_power = paths.get_total_received_power(rec_i + 1)
            mean_time_of_arrival = paths.get_mean_time_of_arrival(rec_i + 1)
            #receiver.position = object.position

            sixParameters=paths.get_6_parameters_for_all_rays(rec_i + 1)
            numRays = sixParameters.shape[0]
            areLOSChannels = paths.is_los(rec_i + 1)
            phases = cir.get_phase_ndarray(rec_i + 1)  # get phases for all rays in degrees
            #go from 0:numRays to support a number of valid rays smaller than the maximum
            allEpisodeData[this_scene_i,rec_i,0:numRays,0:6] = sixParameters
            #allEpisodeData[this_scene_i][rec_i] = sixParameters
            allEpisodeData[this_scene_i,rec_i,0:numRays,6] = areLOSChannels
            allEpisodeData[this_scene_i,rec_i,0:numRays,7] = phases

        rec_i += 1

        # episode.scenes.append(scene)
        print('\rProcessed episode: {} scene: {}, total {} '.format(ep_i, this_scene_i, sc_i + 1), end='')
        sc_i += 1
        this_scene_i += 1
        run_i += 1  # increment loop counter

print()
print('Processed ', run_i, ' scenes (RT simulations)')
